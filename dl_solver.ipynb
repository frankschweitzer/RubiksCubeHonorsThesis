{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(54,)))\n",
    "model.add(Dropout(0.2))  \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(learning_rate=0.0001),\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 54)\n",
      "(30000, 1)\n",
      "0.0\n",
      "81.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = 30000\n",
    "train_samples, train_labels = np.zeros((size,54)), np.zeros((size, 1))\n",
    "\n",
    "f = open('dataset/training.0')\n",
    "for i in range(10000):\n",
    "    tmp_samples = np.asarray(f.readline().rstrip().split(' '))\n",
    "    tmp_samples[tmp_samples == 'w'] = 1\n",
    "    tmp_samples[tmp_samples == 'y'] = 2\n",
    "    tmp_samples[tmp_samples == 'r'] = 3\n",
    "    tmp_samples[tmp_samples == 'b'] = 4\n",
    "    tmp_samples[tmp_samples == 'g'] = 5\n",
    "    tmp_samples[tmp_samples == 'o'] = 6\n",
    "    train_samples[i,:] = tmp_samples.astype(int).reshape(1, 54)\n",
    "    \n",
    "    tmp_labels = f.readline().rstrip().split(' ')\n",
    "    train_labels[i] = (len(tmp_labels))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "f = open('dataset/training.1')\n",
    "for i in range(10000):\n",
    "    tmp_samples = np.asarray(f.readline().rstrip().split(' '))\n",
    "    tmp_samples[tmp_samples == 'w'] = 1\n",
    "    tmp_samples[tmp_samples == 'y'] = 2\n",
    "    tmp_samples[tmp_samples == 'r'] = 3\n",
    "    tmp_samples[tmp_samples == 'b'] = 4\n",
    "    tmp_samples[tmp_samples == 'g'] = 5\n",
    "    tmp_samples[tmp_samples == 'o'] = 6\n",
    "    train_samples[(10000 + i),:] = tmp_samples.astype(int).reshape(1, 54)\n",
    "    \n",
    "    tmp_labels = f.readline().rstrip().split(' ')\n",
    "    train_labels[i] = (len(tmp_labels))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "f = open('dataset/training.2')\n",
    "for i in range(10000):\n",
    "    tmp_samples = np.asarray(f.readline().rstrip().split(' '))\n",
    "    tmp_samples[tmp_samples == 'w'] = 1\n",
    "    tmp_samples[tmp_samples == 'y'] = 2\n",
    "    tmp_samples[tmp_samples == 'r'] = 3\n",
    "    tmp_samples[tmp_samples == 'b'] = 4\n",
    "    tmp_samples[tmp_samples == 'g'] = 5\n",
    "    tmp_samples[tmp_samples == 'o'] = 6\n",
    "    train_samples[(20000 + i),:] = tmp_samples.astype(int).reshape(1, 54)\n",
    "    \n",
    "    tmp_labels = f.readline().rstrip().split(' ')\n",
    "    if len(tmp_labels) == 0:\n",
    "        print(tmp_labels)\n",
    "    train_labels[i] = (len(tmp_labels))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print(train_samples.shape)\n",
    "print(train_labels.shape)\n",
    "print(np.min(train_labels))\n",
    "print(np.max(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 929.2001 - mae: 29.8490 - val_loss: 658.3428 - val_mae: 25.6582\n",
      "Epoch 2/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 933.2493 - mae: 29.9165 - val_loss: 657.1882 - val_mae: 25.6357\n",
      "Epoch 3/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 934.8890 - mae: 29.9309 - val_loss: 656.2568 - val_mae: 25.6175\n",
      "Epoch 4/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 930.9755 - mae: 29.8757 - val_loss: 655.2194 - val_mae: 25.5972\n",
      "Epoch 5/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 930.2937 - mae: 29.8556 - val_loss: 654.8444 - val_mae: 25.5899\n",
      "Epoch 6/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 931.5268 - mae: 29.8862 - val_loss: 654.1393 - val_mae: 25.5761\n",
      "Epoch 7/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 931.1295 - mae: 29.8601 - val_loss: 653.6559 - val_mae: 25.5667\n",
      "Epoch 8/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 936.0591 - mae: 29.9392 - val_loss: 653.5990 - val_mae: 25.5656\n",
      "Epoch 9/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 934.3582 - mae: 29.9178 - val_loss: 653.1024 - val_mae: 25.5559\n",
      "Epoch 10/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 927.3563 - mae: 29.8108 - val_loss: 653.2184 - val_mae: 25.5581\n",
      "Epoch 11/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 933.4713 - mae: 29.9097 - val_loss: 652.6882 - val_mae: 25.5478\n",
      "Epoch 12/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 934.2823 - mae: 29.9118 - val_loss: 652.0533 - val_mae: 25.5353\n",
      "Epoch 13/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 924.5899 - mae: 29.7582 - val_loss: 652.2408 - val_mae: 25.5390\n",
      "Epoch 14/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 935.2477 - mae: 29.9277 - val_loss: 651.9761 - val_mae: 25.5338\n",
      "Epoch 15/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 929.4000 - mae: 29.8361 - val_loss: 651.8347 - val_mae: 25.5310\n",
      "Epoch 16/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 927.2014 - mae: 29.8059 - val_loss: 651.7511 - val_mae: 25.5294\n",
      "Epoch 17/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 928.4000 - mae: 29.8187 - val_loss: 651.7725 - val_mae: 25.5298\n",
      "Epoch 18/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 933.3371 - mae: 29.8961 - val_loss: 651.8658 - val_mae: 25.5317\n",
      "Epoch 19/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 932.8643 - mae: 29.8858 - val_loss: 651.4919 - val_mae: 25.5244\n",
      "Epoch 20/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.1683 - mae: 29.8881 - val_loss: 651.8351 - val_mae: 25.5311\n",
      "Epoch 21/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.0410 - mae: 29.8754 - val_loss: 651.6340 - val_mae: 25.5272\n",
      "Epoch 22/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 928.9612 - mae: 29.8224 - val_loss: 651.7393 - val_mae: 25.5292\n",
      "Epoch 23/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.6743 - mae: 29.8901 - val_loss: 651.8802 - val_mae: 25.5319\n",
      "Epoch 24/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 929.1438 - mae: 29.8300 - val_loss: 651.9189 - val_mae: 25.5327\n",
      "Epoch 25/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.1376 - mae: 29.8899 - val_loss: 651.9839 - val_mae: 25.5340\n",
      "Epoch 26/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 929.4866 - mae: 29.8409 - val_loss: 652.3896 - val_mae: 25.5419\n",
      "Epoch 27/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 931.3213 - mae: 29.8735 - val_loss: 652.1631 - val_mae: 25.5375\n",
      "Epoch 28/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 931.1825 - mae: 29.8574 - val_loss: 652.0456 - val_mae: 25.5351\n",
      "Epoch 29/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.7871 - mae: 29.8851 - val_loss: 652.2648 - val_mae: 25.5395\n",
      "Epoch 30/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.1782 - mae: 29.8876 - val_loss: 651.6319 - val_mae: 25.5271\n",
      "Epoch 31/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 928.2016 - mae: 29.8163 - val_loss: 651.8758 - val_mae: 25.5319\n",
      "Epoch 32/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 930.5464 - mae: 29.8561 - val_loss: 651.8334 - val_mae: 25.5310\n",
      "Epoch 33/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 930.1361 - mae: 29.8531 - val_loss: 651.9429 - val_mae: 25.5332\n",
      "Epoch 34/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.1579 - mae: 29.8872 - val_loss: 651.9680 - val_mae: 25.5337\n",
      "Epoch 35/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 930.5565 - mae: 29.8517 - val_loss: 651.9929 - val_mae: 25.5342\n",
      "Epoch 36/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 929.1921 - mae: 29.8340 - val_loss: 652.0596 - val_mae: 25.5354\n",
      "Epoch 37/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 926.8181 - mae: 29.7965 - val_loss: 652.2810 - val_mae: 25.5398\n",
      "Epoch 38/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 931.5133 - mae: 29.8651 - val_loss: 651.7263 - val_mae: 25.5290\n",
      "Epoch 39/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 927.6557 - mae: 29.8059 - val_loss: 651.7042 - val_mae: 25.5285\n",
      "Epoch 40/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 932.8977 - mae: 29.8852 - val_loss: 651.4622 - val_mae: 25.5239\n",
      "Epoch 41/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 927.9092 - mae: 29.8122 - val_loss: 651.4543 - val_mae: 25.5236\n",
      "Epoch 42/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 931.0901 - mae: 29.8609 - val_loss: 651.5675 - val_mae: 25.5258\n",
      "Epoch 43/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 931.5234 - mae: 29.8661 - val_loss: 651.6304 - val_mae: 25.5270\n",
      "Epoch 44/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 928.4822 - mae: 29.8219 - val_loss: 651.4934 - val_mae: 25.5244\n",
      "Epoch 45/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 934.8533 - mae: 29.9206 - val_loss: 651.6158 - val_mae: 25.5268\n",
      "Epoch 46/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.3080 - mae: 29.8888 - val_loss: 651.3757 - val_mae: 25.5220\n",
      "Epoch 47/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 928.3494 - mae: 29.8230 - val_loss: 651.3564 - val_mae: 25.5217\n",
      "Epoch 48/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 928.7673 - mae: 29.8210 - val_loss: 651.6852 - val_mae: 25.5281\n",
      "Epoch 49/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 932.1984 - mae: 29.8762 - val_loss: 652.1080 - val_mae: 25.5364\n",
      "Epoch 50/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 934.2994 - mae: 29.9126 - val_loss: 651.7356 - val_mae: 25.5291\n",
      "Epoch 51/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 933.7832 - mae: 29.9047 - val_loss: 651.6554 - val_mae: 25.5275\n",
      "Epoch 52/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.6634 - mae: 29.8852 - val_loss: 651.7029 - val_mae: 25.5285\n",
      "Epoch 53/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.8527 - mae: 29.9004 - val_loss: 651.4346 - val_mae: 25.5232\n",
      "Epoch 54/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 935.7227 - mae: 29.9282 - val_loss: 651.2476 - val_mae: 25.5195\n",
      "Epoch 55/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 930.0280 - mae: 29.8423 - val_loss: 651.3019 - val_mae: 25.5205\n",
      "Epoch 56/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 937.2719 - mae: 29.9559 - val_loss: 650.8647 - val_mae: 25.5120\n",
      "Epoch 57/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 935.0587 - mae: 29.9183 - val_loss: 651.4696 - val_mae: 25.5239\n",
      "Epoch 58/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 936.9719 - mae: 29.9518 - val_loss: 651.5988 - val_mae: 25.5264\n",
      "Epoch 59/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 932.5003 - mae: 29.8751 - val_loss: 651.7575 - val_mae: 25.5296\n",
      "Epoch 60/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 934.5363 - mae: 29.9164 - val_loss: 651.5831 - val_mae: 25.5261\n",
      "Epoch 61/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 931.0276 - mae: 29.8496 - val_loss: 651.5065 - val_mae: 25.5246\n",
      "Epoch 62/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.0927 - mae: 29.8949 - val_loss: 651.7509 - val_mae: 25.5294\n",
      "Epoch 63/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 927.8561 - mae: 29.8107 - val_loss: 651.8133 - val_mae: 25.5307\n",
      "Epoch 64/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 935.8407 - mae: 29.9239 - val_loss: 651.7238 - val_mae: 25.5288\n",
      "Epoch 65/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 930.1290 - mae: 29.8520 - val_loss: 651.4991 - val_mae: 25.5244\n",
      "Epoch 66/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 934.5916 - mae: 29.9071 - val_loss: 651.8178 - val_mae: 25.5307\n",
      "Epoch 67/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.6302 - mae: 29.9039 - val_loss: 651.4232 - val_mae: 25.5230\n",
      "Epoch 68/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 925.6431 - mae: 29.7791 - val_loss: 651.5695 - val_mae: 25.5259\n",
      "Epoch 69/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 930.0011 - mae: 29.8423 - val_loss: 651.6561 - val_mae: 25.5276\n",
      "Epoch 70/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 929.7264 - mae: 29.8447 - val_loss: 651.0931 - val_mae: 25.5166\n",
      "Epoch 71/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.1234 - mae: 29.8709 - val_loss: 651.5068 - val_mae: 25.5246\n",
      "Epoch 72/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 924.9129 - mae: 29.7611 - val_loss: 651.7492 - val_mae: 25.5293\n",
      "Epoch 73/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 932.6862 - mae: 29.8826 - val_loss: 651.9446 - val_mae: 25.5332\n",
      "Epoch 74/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 930.0198 - mae: 29.8484 - val_loss: 652.4153 - val_mae: 25.5425\n",
      "Epoch 75/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 927.6845 - mae: 29.8170 - val_loss: 651.6144 - val_mae: 25.5267\n",
      "Epoch 76/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 929.8226 - mae: 29.8433 - val_loss: 651.9382 - val_mae: 25.5331\n",
      "Epoch 77/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 930.4079 - mae: 29.8565 - val_loss: 651.5555 - val_mae: 25.5256\n",
      "Epoch 78/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 932.3552 - mae: 29.8776 - val_loss: 651.5612 - val_mae: 25.5257\n",
      "Epoch 79/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 933.8423 - mae: 29.8971 - val_loss: 651.6638 - val_mae: 25.5278\n",
      "Epoch 80/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 931.6011 - mae: 29.8680 - val_loss: 651.8748 - val_mae: 25.5319\n",
      "Epoch 81/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 933.6415 - mae: 29.8991 - val_loss: 651.8607 - val_mae: 25.5316\n",
      "Epoch 82/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 936.4413 - mae: 29.9444 - val_loss: 652.1850 - val_mae: 25.5379\n",
      "Epoch 83/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 929.1602 - mae: 29.8303 - val_loss: 652.5076 - val_mae: 25.5442\n",
      "Epoch 84/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 938.1854 - mae: 29.9729 - val_loss: 652.0303 - val_mae: 25.5349\n",
      "Epoch 85/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 925.3481 - mae: 29.7734 - val_loss: 652.3290 - val_mae: 25.5408\n",
      "Epoch 86/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 937.1526 - mae: 29.9580 - val_loss: 652.0851 - val_mae: 25.5359\n",
      "Epoch 87/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 935.6005 - mae: 29.9272 - val_loss: 651.7883 - val_mae: 25.5302\n",
      "Epoch 88/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 926.8687 - mae: 29.7925 - val_loss: 652.2162 - val_mae: 25.5385\n",
      "Epoch 89/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 930.3044 - mae: 29.8543 - val_loss: 651.9699 - val_mae: 25.5337\n",
      "Epoch 90/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 929.0784 - mae: 29.8340 - val_loss: 652.1635 - val_mae: 25.5375\n",
      "Epoch 91/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 930.7053 - mae: 29.8615 - val_loss: 651.9893 - val_mae: 25.5341\n",
      "Epoch 92/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 934.6591 - mae: 29.9244 - val_loss: 652.5148 - val_mae: 25.5444\n",
      "Epoch 93/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 932.1637 - mae: 29.8742 - val_loss: 652.2043 - val_mae: 25.5383\n",
      "Epoch 94/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 930.0020 - mae: 29.8455 - val_loss: 652.1241 - val_mae: 25.5367\n",
      "Epoch 95/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 933.5289 - mae: 29.9003 - val_loss: 652.2711 - val_mae: 25.5396\n",
      "Epoch 96/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 926.7867 - mae: 29.8030 - val_loss: 652.2253 - val_mae: 25.5387\n",
      "Epoch 97/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 931.8908 - mae: 29.8764 - val_loss: 652.1185 - val_mae: 25.5366\n",
      "Epoch 98/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 935.4443 - mae: 29.9269 - val_loss: 651.6732 - val_mae: 25.5279\n",
      "Epoch 99/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 929.2762 - mae: 29.8396 - val_loss: 652.1414 - val_mae: 25.5371\n",
      "Epoch 100/100\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 929.9271 - mae: 29.8446 - val_loss: 652.0925 - val_mae: 25.5361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13451c490>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_samples, train_labels, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing Validation Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 54)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "size = 10000\n",
    "val_samples, val_labels = np.zeros((size,54)), np.zeros((size, 1))\n",
    "\n",
    "f = open('dataset/training.8')\n",
    "for i in range(size):\n",
    "    tmp_samples = np.asarray(f.readline().rstrip().split(' '))\n",
    "    tmp_samples[tmp_samples == 'w'] = 1\n",
    "    tmp_samples[tmp_samples == 'y'] = 2\n",
    "    tmp_samples[tmp_samples == 'r'] = 3\n",
    "    tmp_samples[tmp_samples == 'b'] = 4\n",
    "    tmp_samples[tmp_samples == 'g'] = 5\n",
    "    tmp_samples[tmp_samples == 'o'] = 6\n",
    "    val_samples[i,:] = tmp_samples.astype(int).reshape(1, 54)\n",
    "    tmp_labels = f.readline().rstrip().split(' ')\n",
    "    val_labels[i] = (len(tmp_labels))\n",
    "\n",
    "print(val_samples.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1332.1885 - mae: 35.3196\n",
      "test_loss: [1338.357177734375, 35.37590026855469]\n"
     ]
    }
   ],
   "source": [
    "size = 10000\n",
    "test_samples, test_labels = np.zeros((size,54)), np.zeros((size, 1))\n",
    "\n",
    "f = open('dataset/training.9')\n",
    "for i in range(10000):\n",
    "    tmp_samples = np.asarray(f.readline().rstrip().split(' '))\n",
    "    tmp_samples[tmp_samples == 'w'] = 1\n",
    "    tmp_samples[tmp_samples == 'y'] = 2\n",
    "    tmp_samples[tmp_samples == 'r'] = 3\n",
    "    tmp_samples[tmp_samples == 'b'] = 4\n",
    "    tmp_samples[tmp_samples == 'g'] = 5\n",
    "    tmp_samples[tmp_samples == 'o'] = 6\n",
    "    test_samples[i,:] = tmp_samples.astype(int).reshape(1, 54)\n",
    "    tmp_labels = f.readline().rstrip().split(' ')\n",
    "    test_labels[i] = (len(tmp_labels))\n",
    "    \n",
    "test_loss = model.evaluate(test_samples, test_labels)\n",
    "print(f\"test_loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67.]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "[[32.508957]]\n"
     ]
    }
   ],
   "source": [
    "predict_sample = val_samples[0,:].reshape(-1,1).T\n",
    "print(val_labels[0])\n",
    "predictions = model.predict(predict_sample)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d57110a85783f4fcaea870cf452ac838bff2ca8a1a7f156fa31466f57c4b2c5d"
  },
  "kernelspec": {
   "display_name": "Python 3.11.7 ('RubikCube')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
